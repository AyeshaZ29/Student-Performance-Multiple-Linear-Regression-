# -*- coding: utf-8 -*-
"""Student data presentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ixojy6yxfkuRDvGy3YzvvhLUKKDcvoDF

###Importing Necessary Libraries
"""

#loading need libraries
import numpy as np
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats

#preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

"""###Loading Dataset"""

#https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression
df = pd.read_csv('/content/Student_Performance (1).csv')
df

"""##Data Exploration"""

df.head()

df.shape

df.columns

df.dtypes

"""###Missing values"""

df.isnull().sum()

df.duplicated().sum()

df.describe()

df.describe(include='object')

"""###Unique values / Value counts for categoricals"""

df['Extracurricular Activities'].value_counts()

df.info()

for col in df.select_dtypes(include='object').columns:
    print(f"\nUnique Values in {col}: {df[col].unique()}")

for col in df.select_dtypes(include=np.number).columns:
    print(f"Range of {col}: Min = {df[col].min()}, Max = {df[col].max()}")

if "Sleep Hours" in df.columns:
    invalid_sleep = df[(df["Sleep Hours"] < 0) | (df["Sleep Hours"] > 24)]
    print("\nInvalid Sleep Hours Rows:\n", invalid_sleep)

"""##Distribution of Target Variable
A "dist plot" typically refers to a distribution plot, which is a graphical representation of the distribution of a dataset. It helps you understand the underlying probability distribution of the data, providing insights into the central tendency, spread, and shape of the data.
"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.displot(df['Performance Index'], kde=True)  # kde=True adds smooth curve
plt.title("Distribution of Performance Index")
plt.show()

# Group-wise average performance
group_performance = df.groupby('Extracurricular Activities')['Performance Index'].mean()
print(group_performance)

# Bar Plot to visualize comparison
import matplotlib.pyplot as plt

group_performance.plot(kind='bar')
plt.title("Average Performance based on Extracurricular Activities")
plt.xlabel("Extracurricular Activities (Yes/No)")
plt.ylabel("Average Performance Index")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ==========================
# 1️⃣ Basic Data Checks
# ==========================

print("Head of Dataset:\n", df.head())
print("\nDataset Info:\n")
df.info()
print("\nStatistical Summary:\n", df.describe())

print("\nMissing Values:\n", df.isnull().sum())

# Example: Fill numeric missing values with mean, categorical with mode
for col in df.columns:
    if df[col].dtype != 'object':
        df[col].fillna(df[col].mean(), inplace=True)
    else:
        df[col].fillna(df[col].mode()[0], inplace=True)

# Duplicate Check
# ==========================

print("\nDuplicate Rows:", df.duplicated().sum())
df.drop_duplicates(inplace=True)

# Inconsistency Standardization (Categorical Cleanup)
# ==========================

df['Extracurricular Activities'] = df['Extracurricular Activities'].str.strip().str.capitalize()

# Distribution of Each Numeric Feature
# ==========================

for col in df.select_dtypes(include=['int64','float64']).columns:
    plt.figure()
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribution of {col}")
    plt.show()

sns.displot(df['Performance Index'], kde=True)
plt.title("Distribution of Performance Index")
plt.show()

"""###Correlation heatmap"""

df_corr = df.copy()

df_corr['Extracurricular Activities'] = df_corr['Extracurricular Activities'].map({'Yes': 1, 'No': 0})

corr_matrix = df_corr.corr()

plt.figure(figsize=(8,5))
sns.heatmap(df_corr.corr(), annot=True, linewidths=0.5)
plt.title("Correlation Heatmap Including Categorical")
plt.show()

plt.figure(figsize=(8,5))
sns.heatmap(df.drop('Extracurricular Activities', axis=1).corr(), annot=True, linewidths=0.5)
plt.title("Correlation Heatmap (Numeric Only)")
plt.show()

df.hist(figsize=(12,8))
plt.show()

"""##Linear Regression Model
Accuarcy = 98.84

"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# 1 Feature & Target Split
X = df.drop('Performance Index', axis=1)

X['Extracurricular Activities'] = X['Extracurricular Activities'].map({'Yes': 1, 'No': 0})

y = df['Performance Index']

# 2 Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3 Model Training
model = LinearRegression()
model.fit(X_train, y_train)

# 4 Prediction
y_pred = model.predict(X_test)

# 5 Evaluation
print("R2 Score:", r2_score(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print("R2 Score (%):", r2 * 100)
print("MAE:", mean_absolute_error(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

# 6 Model Coefficients
coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])
print("\nModel Coefficients:\n", coefficients)

"""##Decision Tree Regression Model
Accuracy =  97.53 %

"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Model Initialization
dt_model = DecisionTreeRegressor(random_state=42)

# Training
dt_model.fit(X_train, y_train)

# Prediction
y_pred_dt = dt_model.predict(X_test)

# Evaluation
r2_dt = r2_score(y_test, y_pred_dt)
mae_dt = mean_absolute_error(y_test, y_pred_dt)
rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))

print("Decision Tree R2 Score (%):", round(r2_dt * 100, 2), "%")
print("Decision Tree MAE:", round(mae_dt, 2))
print("Decision Tree RMSE:", round(rmse_dt, 2))

"""##SVR (Support Vector Regression) Model
Accuarcy =  98.48 %
"""

from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Initialize SVR Model (RBF kernel by default)
svr_model = SVR(kernel='rbf')

# Train Model
svr_model.fit(X_train, y_train)

# Predict
y_pred_svr = svr_model.predict(X_test)

# Evaluation
r2_svr = r2_score(y_test, y_pred_svr)
mae_svr = mean_absolute_error(y_test, y_pred_svr)
rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_svr))

print("SVR R2 Score (%):", round(r2_svr * 100, 2), "%")
print("SVR MAE:", round(mae_svr, 2))
print("SVR RMSE:", round(rmse_svr, 2))

"""##Random Forest Regression Model
Accuarcy = 98.49 %
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Initialize Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train Model
rf_model.fit(X_train, y_train)

# Predict
y_pred_rf = rf_model.predict(X_test)

# Evaluation
r2_rf = r2_score(y_test, y_pred_rf)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))

print("Random Forest R2 Score (%):", round(r2_rf * 100, 2), "%")
print("Random Forest MAE:", round(mae_rf, 2))
print("Random Forest RMSE:", round(rmse_rf, 2))

"""##Gradient Boosting Model
Accuracy = 98.82 %
"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Initialize Model
gb_model = GradientBoostingRegressor(random_state=42)

#Train Model
gb_model.fit(X_train, y_train)

# Predict
y_pred_gb = gb_model.predict(X_test)

# Evaluation
r2_gb = r2_score(y_test, y_pred_gb)
mae_gb = mean_absolute_error(y_test, y_pred_gb)
rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))

print("Gradient Boosting R2 Score (%):", round(r2_gb * 100, 2), "%")
print("Gradient Boosting MAE:", round(mae_gb, 2))
print("Gradient Boosting RMSE:", round(rmse_gb, 2))